{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{response: \"This paper explores using large language models (LLMs) to predict if a new inorganic crystal structure can be made, which is called synthesizability. The researchers trained LLMs using text descriptions of crystal structures and found that they could predict synthesizability as well as, or even better than, previous specialized machine learning methods. They also showed that LLMs could explain *why* a structure is predicted to be synthesizable or not, providing insights into the chemical principles influencing synthesis. Importantly, this approach can help scientists identify ways to modify hypothetical materials, making them more likely to be synthesized. Ultimately, this research demonstrates a novel way to use LLMs to advance materials design by combining predictive accuracy with human-understandable explanations.\"}\n",
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 85\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: GEMINI_API_KEY not found in .env file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(summerize_pdf(items[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m, in \u001b[0;36mgenerate_questions\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m     39\u001b[0m     generate_questions_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124mGenerate 10 questions based on the paper and the following course content, the questions should be multiple choice questions with 4 answers, the answers should be in the format of a list of strings, the correct answer should be the first answer in the list, it also must be json format, \u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124mdo not mention the course content in the response, do not respond with anything else than the json, it must be serializable by json.loads()\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124m8. **Nuclear Chemistry**\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m+\u001b[39m paper\n\u001b[1;32m     67\u001b[0m     responce \u001b[38;5;241m=\u001b[39m send_to_llm(generate_questions_prompt)\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib64/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib64/python3.12/json/decoder.py:338\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib64/python3.12/json/decoder.py:356\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "import os\n",
    "import pickle\n",
    "from pypdf import PdfReader\n",
    "import requests\n",
    "from classes import ChemrxivItem\n",
    "\n",
    "open_pickle_file = open(\"top_10_items_of_the_week.pkl\", \"rb\")\n",
    "items = pickle.load(open_pickle_file)\n",
    "\n",
    "def get_pdf(item: ChemrxivItem):\n",
    "    if os.path.exists(f\"{item.title}.pdf\"):\n",
    "        pass\n",
    "    else:\n",
    "        url = item.asset.original.url\n",
    "        response = requests.get(url)\n",
    "        with open(f\"{item.title}.pdf\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "    try:\n",
    "        with open(f\"{item.title}.pdf\", \"rb\") as f:\n",
    "            pdf_reader = PdfReader(f)\n",
    "            paper = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                paper += page.extract_text()\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: PDF file not found.\"\n",
    "    return paper\n",
    "\n",
    "    \n",
    "\n",
    "def summerize_pdf(item: ChemrxivItem):\n",
    "    paper = get_pdf(item)\n",
    "    return send_to_llm('Explain the following chemistry paper to an undegrade student, write with 5 sentencesw:' + paper + 'in the format of a {response: \"\"}')\n",
    "\n",
    "def generate_questions(item: ChemrxivItem):\n",
    "    paper = get_pdf(item)\n",
    "    generate_questions_prompt = \"\"\"\n",
    "Generate 10 questions based on the paper and the following course content, the questions should be multiple choice questions with 4 answers, the answers should be in the format of a list of strings, the correct answer should be the first answer in the list, it also must be json format, \n",
    "do not mention the course content in the response, do not respond with anything else than the json, it must be serializable by json.loads()\n",
    "response:\n",
    "\n",
    "\n",
    "{\n",
    "        \"question1\": [answer1, answer2, answer3, answer4],\n",
    "        \"question2\": [answer1, answer2, answer3, answer4],\n",
    "        \"question3\": [answer1, answer2, answer3, answer4],\n",
    "        \"question4\": [answer1, answer2, answer3, answer4],\n",
    "        \"question5\": [answer1, answer2, answer3, answer4],\n",
    "        \"question6\": [answer1, answer2, answer3, answer4],\n",
    "        \"question7\": [answer1, answer2, answer3, answer4],\n",
    "        \"question8\": [answer1, answer2, answer3, answer4],\n",
    "        \"question9\": [answer1, answer2, answer3, answer4],\n",
    "        \"question10\": [answer1, answer2, answer3, answer4]\n",
    "}\n",
    "\n",
    "\n",
    "### Course Content List for CHEM101: General Chemistry I\n",
    "\n",
    "1. **Matter and Measurements**  \n",
    "2. **The Atom**  \n",
    "3. **Bonding**  \n",
    "4. **Chemical Formulas and Equations**  \n",
    "5. **States of Matter**  \n",
    "6. **Thermochemistry and Thermodynamics**  \n",
    "7. **Acid-Base and Oxidation-Reduction Reactions**  \n",
    "8. **Nuclear Chemistry**\n",
    "\"\"\" + paper\n",
    "        \n",
    "    responce = send_to_llm(generate_questions_prompt)\n",
    "\n",
    "    import re\n",
    "    json_pattern = re.compile(r'\\{.*\\}', re.DOTALL)\n",
    "    match = json_pattern.search(responce)\n",
    "    if match:\n",
    "        json_string = match.group(0)\n",
    "        try:\n",
    "            questions = json.loads(json_string)\n",
    "            print(questions)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "    else:\n",
    "        print(\"No JSON found in the response.\")\n",
    "\n",
    "\n",
    "\n",
    "def send_to_llm(context):\n",
    "    load_dotenv(dotenv_path = \".env\")\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if api_key:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        response = client.models.generate_content(model='gemini-2.0-flash-exp', contents=context)\n",
    "        return response.text\n",
    "    else:\n",
    "        print(\"Error: GEMINI_API_KEY not found in .env file.\")\n",
    "\n",
    "\n",
    "\n",
    "print(summerize_pdf(items[0]))\n",
    "print(generate_questions(items[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question1': ['Fine-tuned LLMs can achieve synthesizability predictive performance comparable to bespoke graph neural network models.', 'Fine-tuned LLMs perform worse than bespoke graph neural network models.', 'Fine-tuned LLMs cannot be used for synthesizability predictions.', 'Fine-tuned LLMs require more complex data than graph neural network models.'], 'question2': ['Text embeddings derived from LLMs can enhance synthesizability predictions when used with a PU classifier.', 'Text embeddings are not useful for synthesizability predictions.', 'Text embeddings are less effective than graph-based representations.', 'Text embeddings slow down the model training process.'], 'question3': ['Thermodynamic energy-based predictions often fail to account for materials that are energetically stable but unsynthesized.', 'Thermodynamic energy-based predictions are always accurate.', 'Thermodynamic energy-based predictions are only applicable to metastable materials.', 'Thermodynamic energy-based predictions are not used in material science.'], 'question4': ['The structural description is converted into text using Robocrystallographer.', 'The structural description is converted into text using DFT calculations.', 'The structural description is converted into text using experimental data.', 'The structural description is not converted into text.'], 'question5': ['PU-learning methods use synthesized materials as positive and not-yet-synthesized materials as unlabeled data.', 'PU-learning methods do not differentiate between synthesized and non-synthesized materials.', 'PU-learning methods use synthesized materials as negative data.', 'PU-learning methods require true negative data.'], 'question6': ['The full vector embedding description is more effective for predictions than truncated vector embeddings.', 'Truncated vector embeddings are more effective for predictions than the full vector embedding description.', 'The length of the vector embedding has no effect on prediction accuracy.', 'Only the first few dimensions of the vector embedding are important.'], 'question7': ['LLMs can generate explanations for why a structure is (not) synthesizable.', 'LLMs cannot explain their predictions.', 'LLMs cannot be used to study synthesizability.', 'LLMs only make predictions without providing reasoning.'], 'question8': [\"The model's performance decreases when the input structural information is altered significantly.\", \"The model's performance is not affected by changes in the input structure.\", \"The model's performance increases when the input structural information is altered.\", 'Only large structural changes affect the model.'], 'question9': ['The most important factors for synthesizability prediction include symmetry, element type and geometry.', 'Geometry and bond length have the most significant impact on synthesizability prediction.', 'Only thermodynamic factors affect synthesizability prediction.', 'The length of the text input is the most important factor.'], 'question10': ['Most generated if-then rules from the explanation are self-evaluated as reasonable by the LLM.', 'Most generated if-then rules from the explanation are self-evaluated as unreasonable by the LLM.', 'LLMs cannot evaluate the reasonableness of generated rules.', 'The LLM cannot do any self-evaluation.']}\n"
     ]
    }
   ],
   "source": [
    "item = items[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"question1\": [\n",
      "        \"Large language models (LLMs) trained on text descriptions of crystal structures can achieve comparable synthesizability prediction performance to bespoke graph neural networks.\",\n",
      "        \"LLMs perform significantly worse than bespoke convolutional graph neural network methods for synthesizability prediction.\",\n",
      "         \"LLMs can not be trained on human readable text descriptions.\",\n",
      "        \"LLMs cannot be used to predict crystal structures.\"\n",
      "    ],\n",
      "    \"question2\": [\n",
      "        \"Positive-unlabeled learning, using text embeddings of the structure, can further improve synthesizability prediction accuracy.\",\n",
      "         \"Positive-unlabeled learning decreases synthesizability prediction accuracy.\",\n",
      "        \"Positive-unlabeled learning is not useful for this problem.\",\n",
      "        \"Text embeddings of structure do not impact synthesizability prediction accuracy.\"\n",
      "    ],\n",
      "    \"question3\": [\n",
      "        \"LLMs can generate human-readable explanations for factors governing synthesizability.\",\n",
      "        \"LLMs cannot explain the factors governing synthesizability.\",\n",
      "         \"Explanations generated by LLMs are incomprehensible.\",\n",
      "        \"LLMs explanations have not been useful for synthesizability.\"\n",
      "    ],\n",
      "    \"question4\": [\n",
      "         \"Thermodynamic energy-based predictions for synthesizability often miss metastable candidate materials and fail to account for materials that are energetically stable yet unsynthesized.\",\n",
      "        \"Thermodynamic energy-based predictions are always accurate for synthesizability.\",\n",
      "        \"Thermodynamic stability can always explain synthesis.\",\n",
      "        \"Metastable materials are always synthesizable.\"\n",
      "    ],\n",
      "    \"question5\": [\n",
      "        \"The Materials Project (MP) crystal database was used for training and evaluating models.\",\n",
      "        \"The Materials Project (MP) crystal database was not used in this study.\",\n",
      "         \"Experimental data was used instead of The Materials Project (MP) crystal database.\",\n",
      "         \"No data was used to train the models.\"\n",
      "    ],\n",
      "     \"question6\": [\n",
      "        \"Robocrystallographer was used to convert CIF-formatted structural data into textual descriptions.\",\n",
      "        \"Robocrystallographer was used to convert text to images.\",\n",
      "         \"Robocrystallographer was used to create crystal structures from text.\",\n",
      "         \"Robocrystallographer was not used in the study.\"\n",
      "    ],\n",
      "    \"question7\": [\n",
      "       \"Truncating text embedding vectors decreases model performance, indicating the importance of the full vector.\",\n",
      "        \"Truncating text embedding vectors increases model performance.\",\n",
      "        \"Truncating text embedding vectors has no impact on model performance.\",\n",
      "        \"Truncated vectors are better than the full vector.\"\n",
      "    ],\n",
      "     \"question8\": [\n",
      "       \"Models are highly sensitive to even small structural changes, as evidenced by variations in fractional coordinates.\",\n",
      "        \"Models are not sensitive to structural changes.\",\n",
      "        \"Fractional coordinates do not impact synthesizability prediction.\",\n",
      "         \"Structural changes do not impact synthesizability.\"\n",
      "    ],\n",
      "    \"question9\": [\n",
      "        \"LLM-based approaches can capture aspects of metastability and synthetic accessibility that are neglected by thermodynamic approaches.\",\n",
      "         \"LLM-based approaches are less effective at capturing aspects of metastability and synthetic accessibility than thermodynamic approaches.\",\n",
      "        \"LLM-based approaches are not applicable to metastability and synthetic accessibility.\",\n",
      "       \"Thermodynamic approaches fully capture synthetic accessibility.\"\n",
      "    ],\n",
      "     \"question10\": [\n",
      "         \"Ablation studies show that symmetry and element type information are more important for the model than bond lengths.\",\n",
      "        \"Bond lengths are the most important for the model, symmetry and element type are less important.\",\n",
      "         \"Bond lengths and symmetry are equally important for the model.\",\n",
      "       \"Element type is not important for the model.\"\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(responce)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
